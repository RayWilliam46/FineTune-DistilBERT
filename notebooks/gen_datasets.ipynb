{"cells":[{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# !pip install numpy requests nlpaug","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial Setup"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Install libraries\nimport pandas as pd\nimport numpy as np\nimport nlpaug.augmenter.word as nlpaw\nfrom sklearn.model_selection import train_test_split\nimport tqdm as tqdm\n\n# Import utility functions\nfrom src.utils.data_utils import analyze_dist\nfrom src.utils.data_utils import augment_sentence\nfrom src.utils.data_utils import augment_text\nfrom src.utils.data_utils import combine_toxic_classes\nfrom src.utils.data_utils import get_relevant_words\nfrom src.utils.data_utils import undersample_majority\n\n\n\n# Load the data\ntrain_valid = pd.read_csv('data/raw/train.csv')\ntest = pd.read_csv('data/raw/test.csv')\ntest_labels = pd.read_csv('data/raw/test_labels.csv')\n\n# Check data\nprint('Our (training + valid) data has ', train_valid.shape[0], ' rows.')\nprint('Our test data has ', test.shape[0], ' rows.')\nprint('Our test label data has ', test_labels.shape[0], ' rows.')\n\n# Allow us to see full text (not truncated)\npd.set_option('display.max_colwidth', None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate 'Unbalanced' Dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert from multi-label --> binary classification\ntrain_valid = combine_toxic_classes(train_valid)\n\n# Undersample majority class (class=0)\nunbalanced_df = undersample_majority(train_valid, .42)\n\n# Generate 80-20 train-validation splits\nX_train, X_valid, y_train, y_valid = train_test_split(unbalanced_df['comment_text'],\n                                                      unbalanced_df['isToxic'],\n                                                      train_size=0.8,\n                                                      stratify=unbalanced_df['isToxic'],\n                                                      shuffle=True,\n                                                      random_state=42)\n\n# Output splits of unbalanced dataset\nX_train.to_csv('data/processed/unbalanced_dataset/X_train.csv', index=False)\nX_valid.to_csv('data/processed/unbalanced_dataset/X_valid.csv', index=False)\ny_train.to_csv('data/processed/unbalanced_dataset/y_train.csv', index=False)\ny_valid.to_csv('data/processed/unbalanced_dataset/y_valid.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate 'Balanced' Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the training dataset whose data we will be augmenting\nto_aug = pd.concat([X_train, y_train], axis=1)\n\n# Select the first 128 words of text (the maximum token length we will be using)\n# so that augmentation is only applied to these words.\nto_aug['comment_text'].apply(lambda text: get_relevant_words(text, 128))\n\n# Define nlpaug augmentation object \naug10p = nlpaw.ContextualWordEmbsAug(model_path='bert-base-uncased', aug_min=1, aug_p=0.1, action=\"substitute\")\n\n# Upsample minority class ('isToxic'==1) to create a roughly 50-50 class distribution\nbalanced_df = augment_text(to_aug, aug10p, 8, 3)\n\n# Get splits for Balanced Dataset\nX_train_aug = balanced_df['comment_text']\nX_valid_aug = X_valid\ny_train_aug = balanced_df['isToxic']\ny_valid_aug = y_valid\n\n# Output balanced data\nX_train_aug.to_csv('data/processed/balanced_dataset/X_train_aug.csv', index=False)\nX_valid_aug.to_csv('data/processed/balanced_dataset/X_valid_aug.csv', index=False)\ny_train_aug.to_csv('data/processed/balanced_dataset/y_train_aug.csv', index=False)\ny_valid_aug.to_csv('data/processed/balanced_dataset/y_valid_aug.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generate Test Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge test text data with its labels\ntest_merged = test.merge(test_labels, on='id', how='left')\n\n# Remove masked rows that will not be tested\ntest_merged = test_merged[test_merged['toxic'] != -1]\n\n# Convert from multi-label --> binary classification \ntest_merged = combine_toxic_classes(test_merged)\n\n# Output data\ntest_merged.to_csv('data/processed/test_merged.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}