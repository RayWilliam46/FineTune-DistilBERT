{
 "cells": [
  {
   "metadata": {
    "scrolled": true,
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "# !pip install numpy requests nlpaug"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initial Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "# Install libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nlpaug.augmenter.word as nlpaw\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm as tqdm\n",
    "\n",
    "# Import utility functions\n",
    "from src.utils.data_utils import combine_toxic_classes\n",
    "from src.utils.data_utils import undersample_majority\n",
    "from src.utils.data_utils import analyze_dist\n",
    "from src.utils.data_utils import augment_sentence\n",
    "from src.utils.data_utils import augment_text\n",
    "\n",
    "\n",
    "\n",
    "# Load the data\n",
    "train_valid = pd.read_csv('data/raw/train.csv')\n",
    "test = pd.read_csv('data/raw/test.csv')\n",
    "test_labels = pd.read_csv('data/raw/test_labels.csv')\n",
    "\n",
    "# Check data\n",
    "print('Our (training + valid) data has ', train_valid.shape[0], ' rows.')\n",
    "print('Our test data has ', test.shape[0], ' rows.')\n",
    "print('Our test label data has ', test_labels.shape[0], ' rows.')\n",
    "\n",
    "\n",
    "\n",
    "# Allow us to see full text (not truncated)\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generate Training and Validation Datasets"
   ]
  },
  {
   "metadata": {
    "trusted": false
   },
   "cell_type": "code",
   "source": [
    "# Convert from multi-label --> binary classification\n",
    "train_valid = combine_toxic_classes(train_valid)\n",
    "\n",
    "# Undersample majority class (class=0)\n",
    "unbalanced_df = undersample_majority(train_valid, .42)\n",
    "\n",
    "# Upsample minority class (class=1) to create a roughly 50-50 class distribution\n",
    "aug5p = nlpaw.ContextualWordEmbsAug(model_path='bert-base-uncased', aug_min=1, aug_p=0.05, action=\"substitute\")\n",
    "balanced_df = augment_text(unbalanced_df, aug5p, 8, 3)\n",
    "\n",
    "# Generate 80-20 train-validation splits\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(unbalanced_df['comment_text'],\n",
    "                                                    unbalanced_df['isToxic'],\n",
    "                                                    train_size=0.8,\n",
    "                                                    stratify=unbalanced_df['isToxic'],\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train_aug, X_valid_aug, y_train_aug, y_valid_aug = train_test_split(balanced_df['comment_text'],\n",
    "                                                                    balanced_df['isToxic'],\n",
    "                                                                    train_size=0.8,\n",
    "                                                                    stratify=balanced_df['isToxic'],\n",
    "                                                                    shuffle=True,\n",
    "                                                                    random_state=42)\n",
    "\n",
    "# Output unbalanced data\n",
    "X_train.to_csv('data/processed/unbalanced_dataset/X_train.csv', index=False)\n",
    "X_valid.to_csv('data/processed/unbalanced_dataset/X_valid.csv', index=False)\n",
    "y_train.to_csv('data/processed/unbalanced_dataset/y_train.csv', index=False)\n",
    "y_valid.to_csv('data/processed/unbalanced_dataset/y_valid.csv', index=False)\n",
    "\n",
    "# Output balanced data\n",
    "X_train_aug.to_csv('data/processed/balanced_dataset/X_train_aug.csv', index=False)\n",
    "X_valid_aug.to_csv('data/processed/balanced_dataset/X_valid_aug.csv', index=False)\n",
    "y_train_aug.to_csv('data/processed/balanced_dataset/y_train_aug.csv', index=False)\n",
    "y_valid_aug.to_csv('data/processed/balanced_dataset/y_valid_aug.csv', index=False)\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generate Test Dataset"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Merge test text data with its labels\n",
    "test_merged = test.merge(test_labels, on='id', how='left')\n",
    "\n",
    "# Remove masked rows that will not be tested\n",
    "test_merged = test_merged[test_merged['toxic'] != -1]\n",
    "\n",
    "# Convert from multi-label --> binary classification \n",
    "test_merged = combine_toxic_classes(test_merged)\n",
    "\n",
    "# Output data\n",
    "test_merged.to_csv('data/processed/test_merged.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}